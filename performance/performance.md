# performance

## 分支预测

分支预测是一种计算机处理器中的技术，用于预测处理器在执行条件分支指令时应该采取的下一条指令。这个技术的目的是提高程序的执行效率。

当处理器执行条件分支指令时，它需要根据条件结果来决定下一条要执行的指令。如果处理器等待条件结果返回后再进行判断，就会导致流水线停顿，造成性能下降。为了避免这种情况，分支预测技术被引入。

分支预测器通过分析程序的执行历史和模式来预测分支的结果。它可以基于之前的分支执行情况来猜测下一次分支的结果，并提前将正确的指令送入流水线。如果预测错误，处理器会丢弃已经预测的指令并重新开始执行，这被称为分支预测失败。

分支预测器通常使用两种策略：静态预测和动态预测。静态预测是根据分支指令的特性进行预测，例如，无条件分支总是跳转，而条件分支则根据操作数的关系进行判断。动态预测则基于程序的执行历史和模式来进行预测，例如，使用历史记录来猜测循环中的分支结果。

分支预测对于提高处理器的性能非常重要。通过减少流水线停顿时间，处理器可以更高效地执行指令。然而，分支预测也可能会带来一定的开销，因为预测错误时需要重新执行指令。

分支预测错误通常有两种情况：

1. 预测为"跳转"但实际为"不跳转"：当分支预测器预测某个条件分支会发生跳转（比如if语句）时，但实际上条件判断为假，不需要跳转。这种情况下，处理器预先加载了错误的指令，导致后续的指令执行出错，需要清空流水线并重新开始。

2. 预测为"不跳转"但实际为"跳转"：当分支预测器预测某个条件分支不会发生跳转，但实际上条件判断为真，需要跳转。这种情况下，处理器会错误地继续执行后续的指令，直到发现预测错误并丢弃已经执行的指令，然后重新开始正确的指令序列。

分支预测错误会导致性能下降，因为预测错误时处理器需要回滚一部分操作并重新执行。频繁的分支预测错误会导致流水线的停顿，使处理器无法充分利用硬件资源。

为了减少分支预测错误，现代处理器使用了各种高级的分支预测算法和技术。例如，动态预测器可以根据程序的执行历史和模式进行预测，而分支目标缓冲器可以提前存储分支的目标地址，加速跳转指令的执行。这些技术都旨在提高预测的准确性，并降低分支预测错误的发生率。

```cpp
/* 
下面是一个简单的C++程序示例，用于比较分支预测错误和预测正确时的耗时。程序中使用了一个循环来模拟多次分支预测的情况，对于每个循环迭代，我们在循环内部设置了一个条件分支。
*/
#include <iostream>
#include <chrono>

int main() {
    constexpr int iterations = 1000000; // 循环迭代次数

    int sum = 0;

    auto startWrong = std::chrono::high_resolution_clock::now();
    for (int i = 0; i < iterations; ++i) {
        if (i % 2 == 0) {
            sum += i;
        } else {
            sum -= i;
        }
    }
    auto endWrong = std::chrono::high_resolution_clock::now();
    auto durationWrong = std::chrono::duration_cast<std::chrono::microseconds>(endWrong - startWrong);

    auto startCorrect = std::chrono::high_resolution_clock::now();
    for (int i = 0; i < iterations; ++i) {
        if (i % 2 == 0) {
            sum += i;
        } else {
            sum += i;
        }
    }
    auto endCorrect = std::chrono::high_resolution_clock::now();
    auto durationCorrect = std::chrono::duration_cast<std::chrono::microseconds>(endCorrect - startCorrect);

    std::cout << "分支预测错误时的耗时： " << durationWrong.count() << " 微秒\n";
    std::cout << "分支预测正确时的耗时： " << durationCorrect.count() << " 微秒\n";

    return 0;
}

/*
在此示例中，我们模拟了两个循环，每个循环迭代都包含一个条件分支。在第一个循环中，我们用条件 (i % 2 == 0) 判断 i 是否为偶数，如果是则将其加到 sum 中，否则减去。在第二个循环中，我们用相同的条件 (i % 2 == 0) 判断 i 是否为偶数，但无论结果如何都将其加到 sum 中。

通过比较两个循环的运行时间，可以观察到分支预测错误和预测正确时的耗时差异。在第一个循环中，分支预测器在每次迭代时都需要预测条件 (i % 2 == 0) 的结果，因为结果可能不同。而在第二个循环中，分支预测器始终能够正确地预测到条件 (i % 2 == 0) 的结果，因为结果总是为真。因此，在第一个循环中，分支预测错误的情况会更多，导致性能略微下降。

打印结果：
分支预测错误时的耗时： 7141 微秒
分支预测正确时的耗时： 5343 微秒
*/
```

### switch case的分支预测和 if else的分支预测的性能对比

在一般情况下，switch-case语句的分支预测性能可能比if-else语句的分支预测性能要高。这是因为switch-case语句中的分支通常是基于整数或枚举类型进行判断，而if-else语句中的分支则可以基于更复杂的条件表达式。

Switch-case语句通过跳转表（Jump Table）或查找表（Lookup Table）来实现分支。跳转表是一个数组，根据输入的值直接索引到正确的代码块，因此它不需要做额外的条件判断。这种方式使得编译器和处理器能够更好地进行分支预测，因为它们可以预先知道switch-case中的分支目标地址。

相比之下，if-else语句会根据一个或多个条件表达式进行分支，这些条件表达式必须在运行时进行求值并进行布尔判断。这使得分支预测变得更加复杂，因为处理器必须等待条件结果返回后才能判断下一条要执行的指令。

然而，性能差异也会依赖于具体的场景和实现。在某些情况下，编译器和处理器可能会优化if-else语句的分支预测，使其与switch-case语句的性能接近。